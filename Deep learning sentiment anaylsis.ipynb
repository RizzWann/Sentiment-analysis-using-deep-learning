{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977b55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49b377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:/DS/Datasets/urdu-sentiment-corpus-v1.tsv\",delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2278c5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822eaba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    499\n",
       "P    480\n",
       "O     20\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4de381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Class != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b02b140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    499\n",
       "P    480\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed577a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P\n",
       "5   گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...     N"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df606406",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open(\"E:/DS/Datasets/urdu_stopwords.txt\",'r',encoding=\"utf8\") as file:\n",
    "    for item in file:\n",
    "        stop_words.append(item.partition('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281d9c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "corpus=[]\n",
    "for i in range(len(df)):\n",
    "    doc = re.sub('[^ا-ے]',' ',df.iloc[:,0].values[i])\n",
    "    doc = doc.split()\n",
    "    doc = [word for word in doc if not word in stop_words]\n",
    "    doc =' '.join(doc)\n",
    "    if doc is not None:\n",
    "        corpus.append(doc)\n",
    "num_words = len(corpus) \n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2eacaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>corpous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "      <td>ایٹم بم بنایا ھے بھا ی ایٹم بمب کوٹ لکھپت اتفا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "      <td>چندے انقلاب عمران خان وزیر اعظم بن سکتے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "      <td>سرچ انجن گوگل ب صدر فضا فٹ بلندی چھلانگ عالمی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "      <td>اسکی لہریں یار ْ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...</td>\n",
       "      <td>N</td>\n",
       "      <td>گندی زبان گٹر دماغ جاهل جیالے هو جیالا هو جاهل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class  \\\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P   \n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N   \n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P   \n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P   \n",
       "5   گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...     N   \n",
       "\n",
       "                                             corpous  \n",
       "0  ایٹم بم بنایا ھے بھا ی ایٹم بمب کوٹ لکھپت اتفا...  \n",
       "1            چندے انقلاب عمران خان وزیر اعظم بن سکتے  \n",
       "3  سرچ انجن گوگل ب صدر فضا فٹ بلندی چھلانگ عالمی ...  \n",
       "4                                   اسکی لہریں یار ْ  \n",
       "5  گندی زبان گٹر دماغ جاهل جیالے هو جیالا هو جاهل...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpous'] = corpus\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2648e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"E:/DS/Datasets/urdu-sentiment.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ddefd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98b12b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSize = int(df.shape[0]*0.75)\n",
    "trainSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c8c5b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = int(df.shape[0]*0.75)\n",
    "\n",
    "X_train = df.corpous.iloc[:trainSize].values\n",
    "y_train = df.Class.iloc[:trainSize].values\n",
    "\n",
    "X_test = df.corpous.iloc[trainSize:].values\n",
    "y_test = df.Class.iloc[trainSize:].values\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=128,truncating='post',padding='post')\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=128,truncating='pre',padding='pre')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9f2b1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Embedding,LSTM,SimpleRNN,GRU,Dense,Input,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "77b383b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "X = np.reshape(X, (735, 1, 128))\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ad2c1cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_80 (SimpleRNN)   (None, 1, 200)            65800     \n",
      "                                                                 \n",
      " simple_rnn_81 (SimpleRNN)   (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,001\n",
      "Trainable params: 96,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.7368 - accuracy: 0.5374 - 2s/epoch - 180ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.7373 - accuracy: 0.5224 - 67ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.7366 - accuracy: 0.5020 - 69ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.7337 - accuracy: 0.5238 - 62ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.7271 - accuracy: 0.5224 - 66ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.7106 - accuracy: 0.5265 - 126ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.7072 - accuracy: 0.5347 - 64ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.7085 - accuracy: 0.5252 - 62ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.7142 - accuracy: 0.5415 - 64ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.7096 - accuracy: 0.5265 - 64ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.6976 - accuracy: 0.5265 - 67ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.7018 - accuracy: 0.5456 - 64ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.6912 - accuracy: 0.5524 - 64ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.7165 - accuracy: 0.4952 - 65ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.6924 - accuracy: 0.5537 - 64ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.7046 - accuracy: 0.5306 - 64ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.6894 - accuracy: 0.5469 - 63ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6900 - accuracy: 0.5469 - 64ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6987 - accuracy: 0.5565 - 64ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6928 - accuracy: 0.5374 - 67ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6866 - accuracy: 0.5469 - 69ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.6844 - accuracy: 0.5701 - 70ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.6899 - accuracy: 0.5660 - 66ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.6804 - accuracy: 0.5837 - 72ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.7080 - accuracy: 0.5388 - 68ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.6949 - accuracy: 0.5306 - 67ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.7047 - accuracy: 0.5497 - 78ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.6945 - accuracy: 0.5456 - 74ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.6837 - accuracy: 0.5551 - 71ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.6826 - accuracy: 0.5741 - 69ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.6879 - accuracy: 0.5565 - 65ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.6980 - accuracy: 0.5483 - 64ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.6971 - accuracy: 0.5156 - 67ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.6984 - accuracy: 0.5469 - 69ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.6888 - accuracy: 0.5633 - 70ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.7008 - accuracy: 0.5265 - 70ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.6917 - accuracy: 0.5401 - 74ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.6849 - accuracy: 0.5728 - 70ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.6797 - accuracy: 0.5728 - 69ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.6927 - accuracy: 0.5510 - 72ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.6833 - accuracy: 0.5660 - 76ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.6965 - accuracy: 0.5442 - 75ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.6718 - accuracy: 0.5741 - 72ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.6784 - accuracy: 0.5537 - 68ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.6987 - accuracy: 0.5306 - 69ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.6921 - accuracy: 0.5619 - 68ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.6814 - accuracy: 0.5619 - 63ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.7022 - accuracy: 0.5293 - 65ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.6816 - accuracy: 0.5510 - 71ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.6933 - accuracy: 0.5252 - 71ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.6837 - accuracy: 0.5687 - 74ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.6803 - accuracy: 0.5646 - 68ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.6868 - accuracy: 0.5592 - 63ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.6682 - accuracy: 0.6068 - 77ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.6824 - accuracy: 0.5810 - 63ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.6699 - accuracy: 0.5810 - 66ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.6857 - accuracy: 0.5728 - 66ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.6714 - accuracy: 0.5728 - 77ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.6933 - accuracy: 0.5592 - 75ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.6867 - accuracy: 0.5673 - 65ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.6807 - accuracy: 0.5673 - 65ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.6890 - accuracy: 0.5333 - 65ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.6845 - accuracy: 0.5415 - 66ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.7007 - accuracy: 0.5279 - 64ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.6807 - accuracy: 0.5605 - 66ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.6835 - accuracy: 0.5701 - 65ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.6760 - accuracy: 0.5469 - 63ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.6857 - accuracy: 0.5551 - 64ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.6789 - accuracy: 0.5850 - 64ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.6774 - accuracy: 0.5741 - 72ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.6730 - accuracy: 0.5769 - 76ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.6793 - accuracy: 0.5701 - 72ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.6773 - accuracy: 0.5782 - 68ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.6704 - accuracy: 0.5796 - 63ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.6795 - accuracy: 0.5741 - 65ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.6919 - accuracy: 0.5592 - 65ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.6767 - accuracy: 0.5796 - 66ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.6783 - accuracy: 0.5673 - 66ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.6735 - accuracy: 0.5810 - 65ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.6792 - accuracy: 0.5714 - 65ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.6762 - accuracy: 0.5687 - 66ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 0.6802 - accuracy: 0.5782 - 118ms/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 0.6798 - accuracy: 0.5510 - 66ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 0.6642 - accuracy: 0.5891 - 64ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 0.6769 - accuracy: 0.5633 - 65ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 0.6775 - accuracy: 0.5660 - 65ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 0.6873 - accuracy: 0.5687 - 64ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 0.6778 - accuracy: 0.5687 - 65ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 0.6720 - accuracy: 0.5714 - 65ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 0.6847 - accuracy: 0.5537 - 70ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 0.6756 - accuracy: 0.5782 - 73ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 0.6652 - accuracy: 0.5796 - 67ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 0.6793 - accuracy: 0.5578 - 63ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 0.6700 - accuracy: 0.5741 - 66ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 0.6717 - accuracy: 0.5578 - 64ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 0.6741 - accuracy: 0.5701 - 64ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 0.6877 - accuracy: 0.5483 - 64ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 0.6728 - accuracy: 0.5878 - 65ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 0.6766 - accuracy: 0.5728 - 63ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 0.6864 - accuracy: 0.5524 - 64ms/epoch - 5ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.59       120\n",
      "           1       0.56      0.38      0.45       125\n",
      "\n",
      "    accuracy                           0.53       245\n",
      "   macro avg       0.54      0.53      0.52       245\n",
      "weighted avg       0.54      0.53      0.52       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 128)\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    SimpleRNN(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    SimpleRNN(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X,y,epochs=100,batch_size=60,verbose=2)\n",
    "\n",
    "y_pred = model.predict(np.reshape(X_test, (245, 1, 128)))\n",
    "y_hat = [1 if y >=0.5 else 0 for y in y_pred]\n",
    "\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "14b6044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 1, 200)            198000    \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 100)               90600     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,701\n",
      "Trainable params: 288,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 - 7s - loss: 0.7089 - accuracy: 0.4952 - 7s/epoch - 556ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6884 - accuracy: 0.5524 - 108ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.7189 - accuracy: 0.5088 - 108ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.6942 - accuracy: 0.5333 - 105ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.6954 - accuracy: 0.5293 - 109ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.6824 - accuracy: 0.5701 - 104ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.6898 - accuracy: 0.5565 - 104ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.6802 - accuracy: 0.5782 - 108ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.6688 - accuracy: 0.5918 - 109ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.6867 - accuracy: 0.5537 - 108ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.6851 - accuracy: 0.5660 - 107ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.6930 - accuracy: 0.5605 - 108ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.6788 - accuracy: 0.5660 - 106ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.6821 - accuracy: 0.5619 - 108ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.6835 - accuracy: 0.5646 - 106ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.6773 - accuracy: 0.5646 - 106ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.6903 - accuracy: 0.5374 - 109ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6840 - accuracy: 0.5252 - 108ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6808 - accuracy: 0.5633 - 107ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6847 - accuracy: 0.5388 - 109ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6802 - accuracy: 0.5510 - 108ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.6697 - accuracy: 0.5878 - 111ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.6765 - accuracy: 0.5769 - 105ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.6680 - accuracy: 0.5850 - 108ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.6691 - accuracy: 0.6014 - 108ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.6740 - accuracy: 0.5796 - 109ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.6763 - accuracy: 0.5714 - 109ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.6760 - accuracy: 0.5701 - 112ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.6672 - accuracy: 0.5714 - 109ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.6829 - accuracy: 0.5701 - 110ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.6752 - accuracy: 0.5769 - 113ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.6730 - accuracy: 0.5551 - 110ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.6720 - accuracy: 0.5796 - 109ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.6731 - accuracy: 0.5755 - 110ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.6647 - accuracy: 0.5986 - 108ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.6691 - accuracy: 0.5878 - 115ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.6736 - accuracy: 0.5810 - 105ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.6724 - accuracy: 0.5755 - 114ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.6811 - accuracy: 0.5497 - 118ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.6713 - accuracy: 0.5687 - 112ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.6721 - accuracy: 0.5810 - 114ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.6570 - accuracy: 0.5905 - 111ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.6757 - accuracy: 0.5810 - 116ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.6687 - accuracy: 0.5796 - 113ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.6689 - accuracy: 0.5796 - 172ms/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.6706 - accuracy: 0.5687 - 129ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.6685 - accuracy: 0.5796 - 128ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.6773 - accuracy: 0.5456 - 120ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.6696 - accuracy: 0.5837 - 109ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.6729 - accuracy: 0.5633 - 132ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.6704 - accuracy: 0.5823 - 130ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.6713 - accuracy: 0.5701 - 104ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.6661 - accuracy: 0.5578 - 105ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.6747 - accuracy: 0.5660 - 109ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.6741 - accuracy: 0.5592 - 148ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.6703 - accuracy: 0.5633 - 131ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.6717 - accuracy: 0.5673 - 107ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.6615 - accuracy: 0.5769 - 104ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.6865 - accuracy: 0.5469 - 110ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.6653 - accuracy: 0.5755 - 133ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.6714 - accuracy: 0.5565 - 122ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.6696 - accuracy: 0.5714 - 104ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.6617 - accuracy: 0.5918 - 125ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.6519 - accuracy: 0.6095 - 126ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.6693 - accuracy: 0.5973 - 103ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.6585 - accuracy: 0.5823 - 103ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.6644 - accuracy: 0.5850 - 137ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.6655 - accuracy: 0.5837 - 122ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.6755 - accuracy: 0.5646 - 103ms/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.6737 - accuracy: 0.5769 - 114ms/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.6770 - accuracy: 0.5646 - 124ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.6613 - accuracy: 0.5782 - 123ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.6693 - accuracy: 0.5878 - 109ms/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.6683 - accuracy: 0.5687 - 104ms/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.6484 - accuracy: 0.6177 - 104ms/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.6692 - accuracy: 0.5646 - 114ms/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.6531 - accuracy: 0.5837 - 129ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.6617 - accuracy: 0.6000 - 108ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.6657 - accuracy: 0.6027 - 106ms/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.6755 - accuracy: 0.5891 - 111ms/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.6716 - accuracy: 0.5714 - 116ms/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 0.6653 - accuracy: 0.5728 - 108ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 0.6723 - accuracy: 0.5850 - 108ms/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 0.6646 - accuracy: 0.5850 - 110ms/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 0.6682 - accuracy: 0.5878 - 112ms/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 0.6746 - accuracy: 0.5578 - 125ms/epoch - 10ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 0.6781 - accuracy: 0.5633 - 112ms/epoch - 9ms/step\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 0.6682 - accuracy: 0.6041 - 106ms/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 0.6653 - accuracy: 0.5837 - 109ms/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 0.6581 - accuracy: 0.6068 - 119ms/epoch - 9ms/step\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 0.6678 - accuracy: 0.5891 - 112ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 0.6533 - accuracy: 0.5959 - 108ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 0.6661 - accuracy: 0.5918 - 111ms/epoch - 9ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 0.6654 - accuracy: 0.5755 - 108ms/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 0.6664 - accuracy: 0.5782 - 105ms/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 0.6674 - accuracy: 0.5878 - 128ms/epoch - 10ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 0.6677 - accuracy: 0.5850 - 138ms/epoch - 11ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 0.6528 - accuracy: 0.6204 - 113ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 0.6629 - accuracy: 0.5918 - 103ms/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 0.6674 - accuracy: 0.5810 - 106ms/epoch - 8ms/step\n",
      "8/8 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55       120\n",
      "           1       0.57      0.62      0.59       125\n",
      "\n",
      "    accuracy                           0.57       245\n",
      "   macro avg       0.57      0.57      0.57       245\n",
      "weighted avg       0.57      0.57      0.57       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 128)\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    GRU(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    GRU(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X,y,epochs=100,batch_size=60,verbose=2)\n",
    "\n",
    "y_pred = model.predict(np.reshape(X_test, (245, 1, 128)))\n",
    "y_hat = [1 if y >=0.5 else 0 for y in y_pred]\n",
    "\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "adf701c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 1, 200)            263200    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               120400    \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 383,701\n",
      "Trainable params: 383,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 - 6s - loss: 0.6982 - accuracy: 0.4816 - 6s/epoch - 456ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6882 - accuracy: 0.5497 - 115ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.6917 - accuracy: 0.5224 - 105ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.6902 - accuracy: 0.5361 - 111ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.6853 - accuracy: 0.5605 - 113ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.6863 - accuracy: 0.5293 - 111ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.6789 - accuracy: 0.5905 - 114ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.6808 - accuracy: 0.5565 - 109ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.6865 - accuracy: 0.5306 - 115ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.6763 - accuracy: 0.5578 - 113ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.6813 - accuracy: 0.5415 - 112ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.6762 - accuracy: 0.5701 - 115ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.6843 - accuracy: 0.5510 - 116ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.6844 - accuracy: 0.5714 - 138ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.6805 - accuracy: 0.5578 - 114ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.6762 - accuracy: 0.5728 - 118ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.6789 - accuracy: 0.5687 - 136ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6775 - accuracy: 0.5660 - 133ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6746 - accuracy: 0.5741 - 111ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6770 - accuracy: 0.5741 - 115ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6858 - accuracy: 0.5524 - 121ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.6810 - accuracy: 0.5646 - 131ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.6710 - accuracy: 0.6082 - 115ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.6815 - accuracy: 0.5401 - 110ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.6716 - accuracy: 0.5728 - 125ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.6664 - accuracy: 0.5878 - 126ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.6717 - accuracy: 0.5741 - 125ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.6871 - accuracy: 0.5565 - 110ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.6708 - accuracy: 0.5565 - 113ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.6754 - accuracy: 0.5782 - 130ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.6735 - accuracy: 0.5714 - 128ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.6691 - accuracy: 0.5932 - 120ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.6734 - accuracy: 0.5578 - 112ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.6661 - accuracy: 0.5687 - 126ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.6706 - accuracy: 0.5469 - 139ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.6772 - accuracy: 0.5605 - 115ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.6746 - accuracy: 0.5796 - 112ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.6694 - accuracy: 0.5660 - 111ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.6749 - accuracy: 0.5782 - 118ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.6770 - accuracy: 0.5605 - 131ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.6681 - accuracy: 0.5864 - 124ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.6706 - accuracy: 0.5687 - 113ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.6639 - accuracy: 0.5782 - 113ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.6751 - accuracy: 0.5565 - 112ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.6750 - accuracy: 0.5782 - 121ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.6759 - accuracy: 0.5592 - 112ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.6697 - accuracy: 0.5823 - 106ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.6787 - accuracy: 0.5497 - 108ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.6642 - accuracy: 0.5741 - 107ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.6708 - accuracy: 0.5850 - 112ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.6778 - accuracy: 0.5578 - 111ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.6787 - accuracy: 0.5605 - 106ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.6664 - accuracy: 0.5932 - 108ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.6684 - accuracy: 0.5932 - 132ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.6746 - accuracy: 0.5673 - 132ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.6616 - accuracy: 0.5850 - 135ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.6623 - accuracy: 0.5741 - 113ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.6584 - accuracy: 0.5986 - 121ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.6678 - accuracy: 0.5905 - 131ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.6831 - accuracy: 0.5429 - 111ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.6721 - accuracy: 0.5755 - 109ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.6659 - accuracy: 0.5769 - 108ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.6713 - accuracy: 0.5769 - 109ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.6696 - accuracy: 0.5741 - 116ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.6664 - accuracy: 0.5905 - 121ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.6555 - accuracy: 0.5932 - 114ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.6597 - accuracy: 0.5864 - 114ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.6676 - accuracy: 0.5782 - 124ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.6611 - accuracy: 0.5782 - 126ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.6834 - accuracy: 0.5592 - 197ms/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.6714 - accuracy: 0.5524 - 124ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.6636 - accuracy: 0.5905 - 120ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.6590 - accuracy: 0.5905 - 125ms/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.6731 - accuracy: 0.5850 - 131ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.6664 - accuracy: 0.5578 - 137ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.6709 - accuracy: 0.5769 - 119ms/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.6643 - accuracy: 0.5796 - 129ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.6693 - accuracy: 0.5850 - 135ms/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.6592 - accuracy: 0.5973 - 122ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.6798 - accuracy: 0.5633 - 120ms/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.6613 - accuracy: 0.5796 - 132ms/epoch - 10ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 0.6849 - accuracy: 0.5619 - 124ms/epoch - 10ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 0.6646 - accuracy: 0.6054 - 123ms/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 0.6658 - accuracy: 0.5986 - 128ms/epoch - 10ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 0.6668 - accuracy: 0.5769 - 133ms/epoch - 10ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 0.6672 - accuracy: 0.5782 - 119ms/epoch - 9ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 0.6617 - accuracy: 0.6054 - 110ms/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 0.6602 - accuracy: 0.5932 - 111ms/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 0.6783 - accuracy: 0.5701 - 119ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 0.6597 - accuracy: 0.5918 - 120ms/epoch - 9ms/step\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 0.6584 - accuracy: 0.5714 - 110ms/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 0.6677 - accuracy: 0.5850 - 106ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 0.6666 - accuracy: 0.5864 - 113ms/epoch - 9ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 0.6662 - accuracy: 0.5878 - 118ms/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 0.6675 - accuracy: 0.5891 - 113ms/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 0.6637 - accuracy: 0.5755 - 110ms/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 0.6628 - accuracy: 0.5878 - 107ms/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 0.6540 - accuracy: 0.5796 - 111ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 0.6788 - accuracy: 0.5551 - 119ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 0.6576 - accuracy: 0.5850 - 117ms/epoch - 9ms/step\n",
      "8/8 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.74      0.59       120\n",
      "           1       0.52      0.27      0.36       125\n",
      "\n",
      "    accuracy                           0.50       245\n",
      "   macro avg       0.51      0.51      0.48       245\n",
      "weighted avg       0.51      0.50      0.47       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    LSTM(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    LSTM(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X,y,epochs=100,batch_size=60,verbose=2)\n",
    "\n",
    "y_pred = model.predict(np.reshape(X_test, (245, 1, 128)))\n",
    "y_hat = [1 if y >=0.5 else 0 for y in y_pred]\n",
    "\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2a8992d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 1, 400)           526400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 200)              400800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 927,401\n",
      "Trainable params: 927,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 - 10s - loss: 0.6958 - accuracy: 0.5184 - 10s/epoch - 763ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6923 - accuracy: 0.5442 - 175ms/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.6891 - accuracy: 0.5293 - 178ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.6821 - accuracy: 0.5442 - 175ms/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.6778 - accuracy: 0.5687 - 190ms/epoch - 15ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.6787 - accuracy: 0.5456 - 178ms/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.6847 - accuracy: 0.5741 - 209ms/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.6819 - accuracy: 0.5714 - 203ms/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.6812 - accuracy: 0.5592 - 192ms/epoch - 15ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.6773 - accuracy: 0.5646 - 217ms/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.6694 - accuracy: 0.5728 - 202ms/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.6704 - accuracy: 0.6014 - 209ms/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.6737 - accuracy: 0.5714 - 244ms/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.6592 - accuracy: 0.5946 - 197ms/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.6736 - accuracy: 0.5755 - 194ms/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.6698 - accuracy: 0.5741 - 196ms/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.6521 - accuracy: 0.6000 - 193ms/epoch - 15ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6656 - accuracy: 0.5714 - 212ms/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6669 - accuracy: 0.6041 - 216ms/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6650 - accuracy: 0.5918 - 172ms/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6546 - accuracy: 0.5932 - 177ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.6625 - accuracy: 0.5769 - 190ms/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.6613 - accuracy: 0.5782 - 199ms/epoch - 15ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.6588 - accuracy: 0.6136 - 175ms/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.6660 - accuracy: 0.6109 - 177ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.6708 - accuracy: 0.5728 - 177ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.6591 - accuracy: 0.6095 - 198ms/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.6544 - accuracy: 0.5959 - 180ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.6587 - accuracy: 0.5891 - 179ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.6608 - accuracy: 0.5986 - 177ms/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.6676 - accuracy: 0.5741 - 177ms/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.6514 - accuracy: 0.6163 - 176ms/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.6570 - accuracy: 0.5959 - 188ms/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.6517 - accuracy: 0.6027 - 199ms/epoch - 15ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.6485 - accuracy: 0.6177 - 172ms/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.6614 - accuracy: 0.6027 - 190ms/epoch - 15ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.6628 - accuracy: 0.5973 - 203ms/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.6540 - accuracy: 0.6041 - 173ms/epoch - 13ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.6442 - accuracy: 0.6000 - 186ms/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.6550 - accuracy: 0.6027 - 200ms/epoch - 15ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.6488 - accuracy: 0.6000 - 176ms/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.6490 - accuracy: 0.6027 - 178ms/epoch - 14ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.6499 - accuracy: 0.5918 - 179ms/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.6678 - accuracy: 0.5633 - 189ms/epoch - 15ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.6441 - accuracy: 0.6218 - 180ms/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.6526 - accuracy: 0.6027 - 173ms/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.6661 - accuracy: 0.5891 - 176ms/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.6585 - accuracy: 0.5823 - 176ms/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.6354 - accuracy: 0.6218 - 185ms/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.6368 - accuracy: 0.6286 - 176ms/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.6614 - accuracy: 0.5986 - 206ms/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.6640 - accuracy: 0.6054 - 185ms/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.6451 - accuracy: 0.6095 - 183ms/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.6596 - accuracy: 0.6000 - 197ms/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.6562 - accuracy: 0.6136 - 177ms/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.6413 - accuracy: 0.6150 - 187ms/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.6480 - accuracy: 0.6204 - 199ms/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.6500 - accuracy: 0.5905 - 177ms/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.6509 - accuracy: 0.5973 - 195ms/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.6460 - accuracy: 0.6231 - 181ms/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.6558 - accuracy: 0.6095 - 176ms/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.6509 - accuracy: 0.6136 - 194ms/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.6383 - accuracy: 0.6190 - 189ms/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.6577 - accuracy: 0.5973 - 181ms/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.6322 - accuracy: 0.6150 - 196ms/epoch - 15ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.6603 - accuracy: 0.5973 - 181ms/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.6468 - accuracy: 0.6136 - 190ms/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.6511 - accuracy: 0.5837 - 198ms/epoch - 15ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.6432 - accuracy: 0.5932 - 176ms/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.6440 - accuracy: 0.6122 - 189ms/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.6216 - accuracy: 0.6435 - 197ms/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.6509 - accuracy: 0.5796 - 224ms/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.6457 - accuracy: 0.6041 - 177ms/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.6288 - accuracy: 0.6150 - 190ms/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.6416 - accuracy: 0.6000 - 195ms/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.6345 - accuracy: 0.6354 - 183ms/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.6345 - accuracy: 0.6190 - 177ms/epoch - 14ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.6290 - accuracy: 0.6286 - 201ms/epoch - 15ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.6456 - accuracy: 0.5986 - 175ms/epoch - 13ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.6500 - accuracy: 0.6082 - 177ms/epoch - 14ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.6417 - accuracy: 0.5918 - 190ms/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 0.6362 - accuracy: 0.6299 - 198ms/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 0.6345 - accuracy: 0.6463 - 175ms/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 0.6305 - accuracy: 0.6299 - 195ms/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 0.6392 - accuracy: 0.6231 - 191ms/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 0.6347 - accuracy: 0.6122 - 175ms/epoch - 13ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 0.6408 - accuracy: 0.6122 - 190ms/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 0.6523 - accuracy: 0.5837 - 196ms/epoch - 15ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 0.6280 - accuracy: 0.6177 - 172ms/epoch - 13ms/step\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 0.6364 - accuracy: 0.6190 - 238ms/epoch - 18ms/step\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 0.6437 - accuracy: 0.6041 - 192ms/epoch - 15ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 0.6350 - accuracy: 0.6231 - 197ms/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 0.6354 - accuracy: 0.6109 - 250ms/epoch - 19ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 0.6453 - accuracy: 0.5837 - 194ms/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 0.6173 - accuracy: 0.6531 - 233ms/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 0.6270 - accuracy: 0.6327 - 199ms/epoch - 15ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 0.6357 - accuracy: 0.6286 - 194ms/epoch - 15ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 0.6346 - accuracy: 0.6204 - 218ms/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 0.6415 - accuracy: 0.6231 - 189ms/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 0.6430 - accuracy: 0.6204 - 197ms/epoch - 15ms/step\n",
      "8/8 [==============================] - 3s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.62      0.55       120\n",
      "           1       0.52      0.39      0.45       125\n",
      "\n",
      "    accuracy                           0.51       245\n",
      "   macro avg       0.51      0.51      0.50       245\n",
      "weighted avg       0.51      0.51      0.50       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Bidirectional(LSTM(200, dropout=0.3, activation='tanh', return_sequences=True)),\n",
    "    Bidirectional(LSTM(100, dropout=0.3, activation='tanh')),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X,y,epochs=100,batch_size=60,verbose=2)\n",
    "\n",
    "y_pred = model.predict(np.reshape(X_test, (245, 1, 128)))\n",
    "y_hat = [1 if y >=0.5 else 0 for y in y_pred]\n",
    "\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c4920",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd2c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Embedding,GRU,Dense,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72dcfaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bda19a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>corpous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "      <td>ایٹم بم بنایا ھے بھا ی ایٹم بمب کوٹ لکھپت اتفا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "      <td>چندے انقلاب عمران خان وزیر اعظم بن سکتے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "      <td>سرچ انجن گوگل ب صدر فضا فٹ بلندی چھلانگ عالمی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "      <td>اسکی لہریں یار ْ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...</td>\n",
       "      <td>N</td>\n",
       "      <td>گندی زبان گٹر دماغ جاهل جیالے هو جیالا هو جاهل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class  \\\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P   \n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N   \n",
       "2  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P   \n",
       "3    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P   \n",
       "4   گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...     N   \n",
       "\n",
       "                                             corpous  \n",
       "0  ایٹم بم بنایا ھے بھا ی ایٹم بمب کوٹ لکھپت اتفا...  \n",
       "1            چندے انقلاب عمران خان وزیر اعظم بن سکتے  \n",
       "2  سرچ انجن گوگل ب صدر فضا فٹ بلندی چھلانگ عالمی ...  \n",
       "3                                   اسکی لہریں یار ْ  \n",
       "4  گندی زبان گٹر دماغ جاهل جیالے هو جیالا هو جاهل...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:/DS/Datasets/urdu-sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99de11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9123ceab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546495, 1558650)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df.corpous.apply(lambda x: str(x).split()) # tokenizing\n",
    "\n",
    "model_w2v = Word2Vec(corpus, vector_size=300,  window=5)\n",
    "\n",
    "model_w2v.train(corpus, total_examples= len(df.corpous), epochs=150)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7192e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('لوگوں', 0.7340641021728516),\n",
       " ('منہ', 0.7099151611328125),\n",
       " ('امریکہ', 0.6859112977981567),\n",
       " ('گھر', 0.6813095808029175),\n",
       " ('جواب', 0.6527116894721985),\n",
       " ('اچھی', 0.6017876267433167),\n",
       " ('ٹوٹ', 0.5949305891990662),\n",
       " ('فا', 0.5865015983581543),\n",
       " ('لفظ', 0.5750141739845276),\n",
       " ('حق', 0.5624004006385803)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive='زبان')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f246ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('مانگنے', 0.752217173576355),\n",
       " ('سکتے', 0.690217912197113),\n",
       " ('کنٹینر', 0.6728219389915466),\n",
       " ('دھرنے', 0.6409998536109924),\n",
       " ('تبدیلی', 0.6405375599861145),\n",
       " ('دس', 0.6199865937232971),\n",
       " ('چندے', 0.5991798639297485),\n",
       " ('کیلیے', 0.5940641760826111),\n",
       " ('عمران', 0.5888068079948425),\n",
       " ('مریم', 0.5807701945304871)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive='چندہ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01179b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "                         \n",
    "            continue\n",
    "    if count != 0.:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f405f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 300)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(corpus), 300))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    wordvec_arrays[i,:] = word_vector(corpus[i], 300)\n",
    "    \n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef1d6b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainSize = int(df.shape[0]*0.75)\n",
    "num_words = len(corpus)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.corpous, df.Class,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test  = X_test.astype(str)\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=128,truncating='post',padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=128,truncating='pre',padding='pre')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "481ae4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 128, 300)          294000    \n",
      "                                                                 \n",
      " gru_22 (GRU)                (None, 128, 200)          301200    \n",
      "                                                                 \n",
      " gru_23 (GRU)                (None, 100)               90600     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 685,901\n",
      "Trainable params: 391,901\n",
      "Non-trainable params: 294,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "12/12 - 18s - loss: 0.7294 - Accuracy: 0.5029 - precision: 0.4899 - recall: 0.4358 - val_loss: 0.7048 - val_Accuracy: 0.4932 - val_precision: 0.4949 - val_recall: 0.9932 - 18s/epoch - 1s/step\n",
      "Epoch 2/30\n",
      "12/12 - 7s - loss: 0.7016 - Accuracy: 0.5058 - precision: 0.4953 - recall: 0.4687 - val_loss: 0.6950 - val_Accuracy: 0.5000 - val_precision: 0.4444 - val_recall: 0.0274 - 7s/epoch - 570ms/step\n",
      "Epoch 3/30\n",
      "12/12 - 7s - loss: 0.6925 - Accuracy: 0.5248 - precision: 0.5191 - recall: 0.3642 - val_loss: 0.6936 - val_Accuracy: 0.5306 - val_precision: 0.5150 - val_recall: 0.9384 - 7s/epoch - 576ms/step\n",
      "Epoch 4/30\n",
      "12/12 - 8s - loss: 0.6976 - Accuracy: 0.4971 - precision: 0.4924 - recall: 0.8657 - val_loss: 0.6945 - val_Accuracy: 0.4864 - val_precision: 0.3684 - val_recall: 0.0479 - 8s/epoch - 648ms/step\n",
      "Epoch 5/30\n",
      "12/12 - 7s - loss: 0.7003 - Accuracy: 0.5073 - precision: 0.4889 - recall: 0.1970 - val_loss: 0.6948 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.9863 - 7s/epoch - 587ms/step\n",
      "Epoch 6/30\n",
      "12/12 - 8s - loss: 0.6952 - Accuracy: 0.4752 - precision: 0.4665 - recall: 0.4985 - val_loss: 0.6948 - val_Accuracy: 0.4626 - val_precision: 0.4651 - val_recall: 0.5479 - 8s/epoch - 653ms/step\n",
      "Epoch 7/30\n",
      "12/12 - 7s - loss: 0.6946 - Accuracy: 0.4913 - precision: 0.4602 - recall: 0.2418 - val_loss: 0.6947 - val_Accuracy: 0.4592 - val_precision: 0.4716 - val_recall: 0.7397 - 7s/epoch - 594ms/step\n",
      "Epoch 8/30\n",
      "12/12 - 8s - loss: 0.6934 - Accuracy: 0.4956 - precision: 0.4825 - recall: 0.4119 - val_loss: 0.6943 - val_Accuracy: 0.4694 - val_precision: 0.4627 - val_recall: 0.4247 - 8s/epoch - 654ms/step\n",
      "Epoch 9/30\n",
      "12/12 - 7s - loss: 0.6962 - Accuracy: 0.5073 - precision: 0.4000 - recall: 0.0179 - val_loss: 0.6943 - val_Accuracy: 0.4864 - val_precision: 0.4902 - val_recall: 0.8562 - 7s/epoch - 594ms/step\n",
      "Epoch 10/30\n",
      "12/12 - 8s - loss: 0.7013 - Accuracy: 0.4796 - precision: 0.4743 - recall: 0.5791 - val_loss: 0.6954 - val_Accuracy: 0.5102 - val_precision: 0.5385 - val_recall: 0.0959 - 8s/epoch - 631ms/step\n",
      "Epoch 11/30\n",
      "12/12 - 7s - loss: 0.6928 - Accuracy: 0.5015 - precision: 0.4653 - recall: 0.1403 - val_loss: 0.6950 - val_Accuracy: 0.5068 - val_precision: 0.5018 - val_recall: 0.9658 - 7s/epoch - 585ms/step\n",
      "Epoch 12/30\n",
      "12/12 - 8s - loss: 0.6945 - Accuracy: 0.5146 - precision: 0.5026 - recall: 0.8716 - val_loss: 0.6945 - val_Accuracy: 0.5204 - val_precision: 0.5714 - val_recall: 0.1370 - 8s/epoch - 647ms/step\n",
      "Epoch 13/30\n",
      "12/12 - 7s - loss: 0.6958 - Accuracy: 0.5131 - precision: 1.0000 - recall: 0.0030 - val_loss: 0.6937 - val_Accuracy: 0.4762 - val_precision: 0.4714 - val_recall: 0.4521 - 7s/epoch - 591ms/step\n",
      "Epoch 14/30\n",
      "12/12 - 8s - loss: 0.6948 - Accuracy: 0.5117 - precision: 0.5008 - recall: 0.8896 - val_loss: 0.6938 - val_Accuracy: 0.4830 - val_precision: 0.4741 - val_recall: 0.3767 - 8s/epoch - 665ms/step\n",
      "Epoch 15/30\n",
      "12/12 - 7s - loss: 0.6938 - Accuracy: 0.5160 - precision: 0.5652 - recall: 0.0388 - val_loss: 0.6943 - val_Accuracy: 0.4966 - val_precision: 0.4884 - val_recall: 0.2877 - 7s/epoch - 588ms/step\n",
      "Epoch 16/30\n",
      "12/12 - 7s - loss: 0.6919 - Accuracy: 0.5190 - precision: 0.5084 - recall: 0.4537 - val_loss: 0.6945 - val_Accuracy: 0.5136 - val_precision: 0.5055 - val_recall: 0.9452 - 7s/epoch - 597ms/step\n",
      "Epoch 17/30\n",
      "12/12 - 8s - loss: 0.6942 - Accuracy: 0.4971 - precision: 0.4750 - recall: 0.2836 - val_loss: 0.6941 - val_Accuracy: 0.4660 - val_precision: 0.4789 - val_recall: 0.8562 - 8s/epoch - 635ms/step\n",
      "Epoch 18/30\n",
      "12/12 - 8s - loss: 0.6984 - Accuracy: 0.4942 - precision: 0.4884 - recall: 0.6925 - val_loss: 0.6951 - val_Accuracy: 0.4898 - val_precision: 0.4000 - val_recall: 0.0548 - 8s/epoch - 670ms/step\n",
      "Epoch 19/30\n",
      "12/12 - 10s - loss: 0.6976 - Accuracy: 0.4694 - precision: 0.4264 - recall: 0.2507 - val_loss: 0.6933 - val_Accuracy: 0.5170 - val_precision: 0.5082 - val_recall: 0.8493 - 10s/epoch - 838ms/step\n",
      "Epoch 20/30\n",
      "12/12 - 9s - loss: 0.6943 - Accuracy: 0.4913 - precision: 0.4708 - recall: 0.3373 - val_loss: 0.6938 - val_Accuracy: 0.4762 - val_precision: 0.4048 - val_recall: 0.1164 - 9s/epoch - 725ms/step\n",
      "Epoch 21/30\n",
      "12/12 - 7s - loss: 0.6930 - Accuracy: 0.5160 - precision: 0.5146 - recall: 0.1582 - val_loss: 0.6930 - val_Accuracy: 0.4932 - val_precision: 0.4805 - val_recall: 0.2534 - 7s/epoch - 611ms/step\n",
      "Epoch 22/30\n",
      "12/12 - 8s - loss: 0.6943 - Accuracy: 0.5102 - precision: 0.4979 - recall: 0.3612 - val_loss: 0.6927 - val_Accuracy: 0.5306 - val_precision: 0.5233 - val_recall: 0.6164 - 8s/epoch - 653ms/step\n",
      "Epoch 23/30\n",
      "12/12 - 7s - loss: 0.6916 - Accuracy: 0.4942 - precision: 0.4874 - recall: 0.6328 - val_loss: 0.6943 - val_Accuracy: 0.4966 - val_precision: 0.4375 - val_recall: 0.0479 - 7s/epoch - 592ms/step\n",
      "Epoch 24/30\n",
      "12/12 - 7s - loss: 0.6946 - Accuracy: 0.5058 - precision: 0.4924 - recall: 0.3851 - val_loss: 0.6938 - val_Accuracy: 0.4762 - val_precision: 0.4565 - val_recall: 0.2877 - 7s/epoch - 607ms/step\n",
      "Epoch 25/30\n",
      "12/12 - 7s - loss: 0.7003 - Accuracy: 0.4810 - precision: 0.4571 - recall: 0.3343 - val_loss: 0.6935 - val_Accuracy: 0.4796 - val_precision: 0.4752 - val_recall: 0.4589 - 7s/epoch - 621ms/step\n",
      "Epoch 26/30\n",
      "12/12 - 7s - loss: 0.6955 - Accuracy: 0.4796 - precision: 0.3659 - recall: 0.0896 - val_loss: 0.6937 - val_Accuracy: 0.4966 - val_precision: 0.4943 - val_recall: 0.5959 - 7s/epoch - 583ms/step\n",
      "Epoch 27/30\n",
      "12/12 - 15s - loss: 0.6972 - Accuracy: 0.5044 - precision: 0.4955 - recall: 0.8239 - val_loss: 0.6943 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.0205 - 15s/epoch - 1s/step\n",
      "Epoch 28/30\n",
      "12/12 - 8s - loss: 0.6942 - Accuracy: 0.5073 - precision: 0.2000 - recall: 0.0030 - val_loss: 0.6934 - val_Accuracy: 0.4932 - val_precision: 0.4286 - val_recall: 0.0616 - 8s/epoch - 699ms/step\n",
      "Epoch 29/30\n",
      "12/12 - 8s - loss: 0.6948 - Accuracy: 0.4971 - precision: 0.4828 - recall: 0.3761 - val_loss: 0.6931 - val_Accuracy: 0.5068 - val_precision: 0.5294 - val_recall: 0.0616 - 8s/epoch - 638ms/step\n",
      "Epoch 30/30\n",
      "12/12 - 8s - loss: 0.6969 - Accuracy: 0.5204 - precision: 0.5288 - recall: 0.1642 - val_loss: 0.6927 - val_Accuracy: 0.5204 - val_precision: 0.5112 - val_recall: 0.7808 - 8s/epoch - 674ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(wordvec_arrays),\n",
    "                            output_dim=300,\n",
    "                            weights=[wordvec_arrays],\n",
    "                            input_length=128,\n",
    "                            trainable=False),\n",
    "    GRU(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    GRU(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Accuracy',\n",
    "                                                                     'Precision',\n",
    "                                                                     'Recall',\n",
    "                                                                   \n",
    "                                                \n",
    "                                                                    ])\n",
    "print(model.summary())\n",
    "\n",
    "hist = model.fit(X_train,y_train,epochs=30,batch_size=60,verbose=2,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0540ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5204081535339355 \n",
      "Precision : 0.5288461446762085 \n",
      "Recall : 0.16417910158634186 \n",
      "F1Score : 0.2505694716854425\n"
     ]
    }
   ],
   "source": [
    "accuracy = hist.history['Accuracy'][-1]\n",
    "precision = hist.history['precision'][-1]\n",
    "recall = hist.history['recall'][-1]\n",
    "F1Scrore = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"Accuracy : {accuracy} \\nPrecision : {precision} \\nRecall : {recall} \\nF1Score : {F1Scrore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a36e0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    " from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9cfdc204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546495, 1558650)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df.corpous.apply(lambda x: str(x).split()) # tokenizing\n",
    "\n",
    "model_w2v = FastText(corpus, vector_size=300,  window=5)\n",
    "\n",
    "model_w2v.train(corpus, total_examples= len(df.corpous), epochs=150)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "446e3ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('لوگوں', 0.741570234298706),\n",
       " ('گھر', 0.6810804009437561),\n",
       " ('منہ', 0.6359058618545532),\n",
       " ('شکریہ', 0.5818443298339844),\n",
       " ('جان', 0.5818175673484802),\n",
       " ('فا', 0.5722193717956543),\n",
       " ('پتا', 0.5632427930831909),\n",
       " ('ویسے', 0.5613620281219482),\n",
       " ('امریکہ', 0.5609874129295349),\n",
       " ('لفظ', 0.5557683706283569)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive='زبان')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4fa3351a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('چندے', 0.81256502866745),\n",
       " ('مانگنے', 0.7959380745887756),\n",
       " ('سکتے', 0.7338665723800659),\n",
       " ('کنٹینر', 0.7073994874954224),\n",
       " ('بغیر', 0.652493417263031),\n",
       " ('عمران', 0.5894601941108704),\n",
       " ('تبدیلی', 0.5885247588157654),\n",
       " ('جگہ', 0.5880036950111389),\n",
       " ('دھرنے', 0.5824985504150391),\n",
       " ('انقلاب', 0.5786046981811523)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive='چندہ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "756f015c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 300)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(corpus), 300))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    wordvec_arrays[i,:] = word_vector(corpus[i], 300)\n",
    "    \n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "00220534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainSize = int(df.shape[0]*0.75)\n",
    "num_words = len(corpus)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.corpous, df.Class,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test  = X_test.astype(str)\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=128,truncating='post',padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=128,truncating='pre',padding='pre')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3326415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 128, 300)          294000    \n",
      "                                                                 \n",
      " gru_24 (GRU)                (None, 128, 200)          301200    \n",
      "                                                                 \n",
      " gru_25 (GRU)                (None, 100)               90600     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 685,901\n",
      "Trainable params: 391,901\n",
      "Non-trainable params: 294,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "12/12 - 21s - loss: 0.7051 - Accuracy: 0.5000 - precision: 0.4730 - recall: 0.2090 - val_loss: 0.6968 - val_Accuracy: 0.4762 - val_precision: 0.4846 - val_recall: 0.8630 - 21s/epoch - 2s/step\n",
      "Epoch 2/30\n",
      "12/12 - 7s - loss: 0.6970 - Accuracy: 0.5131 - precision: 0.5008 - recall: 0.8896 - val_loss: 0.6992 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 542ms/step\n",
      "Epoch 3/30\n",
      "12/12 - 7s - loss: 0.6976 - Accuracy: 0.5146 - precision: 1.0000 - recall: 0.0060 - val_loss: 0.6945 - val_Accuracy: 0.4694 - val_precision: 0.4500 - val_recall: 0.3082 - 7s/epoch - 580ms/step\n",
      "Epoch 4/30\n",
      "12/12 - 8s - loss: 0.6947 - Accuracy: 0.4825 - precision: 0.4858 - recall: 0.9731 - val_loss: 0.6936 - val_Accuracy: 0.4864 - val_precision: 0.4510 - val_recall: 0.1575 - 8s/epoch - 640ms/step\n",
      "Epoch 5/30\n",
      "12/12 - 7s - loss: 0.6927 - Accuracy: 0.5262 - precision: 0.6250 - recall: 0.0746 - val_loss: 0.6953 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 603ms/step\n",
      "Epoch 6/30\n",
      "12/12 - 7s - loss: 0.6980 - Accuracy: 0.5117 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6945 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.0068 - 7s/epoch - 621ms/step\n",
      "Epoch 7/30\n",
      "12/12 - 8s - loss: 0.6932 - Accuracy: 0.4942 - precision: 0.4885 - recall: 0.7642 - val_loss: 0.6941 - val_Accuracy: 0.4694 - val_precision: 0.4653 - val_recall: 0.4589 - 8s/epoch - 639ms/step\n",
      "Epoch 8/30\n",
      "12/12 - 8s - loss: 0.6938 - Accuracy: 0.4840 - precision: 0.4691 - recall: 0.4299 - val_loss: 0.6944 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.0068 - 8s/epoch - 655ms/step\n",
      "Epoch 9/30\n",
      "12/12 - 7s - loss: 0.6936 - Accuracy: 0.5073 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6946 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 601ms/step\n",
      "Epoch 10/30\n",
      "12/12 - 7s - loss: 0.6938 - Accuracy: 0.5102 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6954 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 597ms/step\n",
      "Epoch 11/30\n",
      "12/12 - 7s - loss: 0.6941 - Accuracy: 0.5058 - precision: 0.3000 - recall: 0.0090 - val_loss: 0.6942 - val_Accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 597ms/step\n",
      "Epoch 12/30\n",
      "12/12 - 8s - loss: 0.6931 - Accuracy: 0.5248 - precision: 0.5100 - recall: 0.7582 - val_loss: 0.6934 - val_Accuracy: 0.5136 - val_precision: 0.5294 - val_recall: 0.1849 - 8s/epoch - 650ms/step\n",
      "Epoch 13/30\n",
      "12/12 - 7s - loss: 0.6927 - Accuracy: 0.5087 - precision: 0.4878 - recall: 0.1194 - val_loss: 0.6947 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 547ms/step\n",
      "Epoch 14/30\n",
      "12/12 - 7s - loss: 0.6957 - Accuracy: 0.4650 - precision: 0.3798 - recall: 0.1463 - val_loss: 0.6934 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.0068 - 7s/epoch - 609ms/step\n",
      "Epoch 15/30\n",
      "12/12 - 8s - loss: 0.6952 - Accuracy: 0.5117 - precision: 0.5000 - recall: 0.0179 - val_loss: 0.6939 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 8s/epoch - 631ms/step\n",
      "Epoch 16/30\n",
      "12/12 - 8s - loss: 0.6940 - Accuracy: 0.4810 - precision: 0.4118 - recall: 0.1463 - val_loss: 0.6933 - val_Accuracy: 0.5000 - val_precision: 0.4444 - val_recall: 0.0274 - 8s/epoch - 637ms/step\n",
      "Epoch 17/30\n",
      "12/12 - 8s - loss: 0.6961 - Accuracy: 0.5044 - precision: 0.4648 - recall: 0.0985 - val_loss: 0.6938 - val_Accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 8s/epoch - 632ms/step\n",
      "Epoch 18/30\n",
      "12/12 - 7s - loss: 0.6944 - Accuracy: 0.5058 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6938 - val_Accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 7s/epoch - 603ms/step\n",
      "Epoch 19/30\n",
      "12/12 - 8s - loss: 0.6962 - Accuracy: 0.4752 - precision: 0.4776 - recall: 0.7970 - val_loss: 0.6936 - val_Accuracy: 0.4932 - val_precision: 0.4819 - val_recall: 0.2740 - 8s/epoch - 630ms/step\n",
      "Epoch 20/30\n",
      "12/12 - 7s - loss: 0.6964 - Accuracy: 0.4985 - precision: 0.4043 - recall: 0.0567 - val_loss: 0.6933 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.0137 - 7s/epoch - 609ms/step\n",
      "Epoch 21/30\n",
      "12/12 - 7s - loss: 0.6939 - Accuracy: 0.4913 - precision: 0.4840 - recall: 0.6328 - val_loss: 0.6933 - val_Accuracy: 0.5102 - val_precision: 0.6667 - val_recall: 0.0274 - 7s/epoch - 607ms/step\n",
      "Epoch 22/30\n",
      "12/12 - 7s - loss: 0.6948 - Accuracy: 0.5058 - precision: 0.3889 - recall: 0.0209 - val_loss: 0.6937 - val_Accuracy: 0.5136 - val_precision: 0.5714 - val_recall: 0.0822 - 7s/epoch - 547ms/step\n",
      "Epoch 23/30\n",
      "12/12 - 7s - loss: 0.6942 - Accuracy: 0.4767 - precision: 0.4781 - recall: 0.7493 - val_loss: 0.6939 - val_Accuracy: 0.4966 - val_precision: 0.4667 - val_recall: 0.0959 - 7s/epoch - 603ms/step\n",
      "Epoch 24/30\n",
      "12/12 - 6s - loss: 0.6942 - Accuracy: 0.5044 - precision: 0.4138 - recall: 0.0358 - val_loss: 0.6951 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 6s/epoch - 538ms/step\n",
      "Epoch 25/30\n",
      "12/12 - 7s - loss: 0.6928 - Accuracy: 0.5058 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6946 - val_Accuracy: 0.4796 - val_precision: 0.4653 - val_recall: 0.3219 - 7s/epoch - 569ms/step\n",
      "Epoch 26/30\n",
      "12/12 - 7s - loss: 0.6938 - Accuracy: 0.4927 - precision: 0.4844 - recall: 0.5552 - val_loss: 0.6948 - val_Accuracy: 0.5034 - val_precision: 0.5000 - val_recall: 0.0753 - 7s/epoch - 566ms/step\n",
      "Epoch 27/30\n",
      "12/12 - 7s - loss: 0.6944 - Accuracy: 0.4913 - precision: 0.4727 - recall: 0.3612 - val_loss: 0.6950 - val_Accuracy: 0.5068 - val_precision: 0.5294 - val_recall: 0.0616 - 7s/epoch - 544ms/step\n",
      "Epoch 28/30\n",
      "12/12 - 7s - loss: 0.6945 - Accuracy: 0.4927 - precision: 0.3898 - recall: 0.0687 - val_loss: 0.6947 - val_Accuracy: 0.4830 - val_precision: 0.4516 - val_recall: 0.1918 - 7s/epoch - 599ms/step\n",
      "Epoch 29/30\n",
      "12/12 - 7s - loss: 0.6938 - Accuracy: 0.4694 - precision: 0.4530 - recall: 0.4030 - val_loss: 0.6941 - val_Accuracy: 0.5000 - val_precision: 0.4706 - val_recall: 0.0548 - 7s/epoch - 562ms/step\n",
      "Epoch 30/30\n",
      "12/12 - 7s - loss: 0.6937 - Accuracy: 0.5131 - precision: 0.5556 - recall: 0.0149 - val_loss: 0.6940 - val_Accuracy: 0.5000 - val_precision: 0.3333 - val_recall: 0.0068 - 7s/epoch - 595ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(wordvec_arrays),\n",
    "                            output_dim=300,\n",
    "                            weights=[wordvec_arrays],\n",
    "                            input_length=128,\n",
    "                            trainable=False),\n",
    "    GRU(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    GRU(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Accuracy',\n",
    "                                                                     'Precision',\n",
    "                                                                     'Recall',\n",
    "                                                                   \n",
    "                                                \n",
    "                                                                    ])\n",
    "print(model.summary())\n",
    "\n",
    "hist = model.fit(X_train,y_train,epochs=30,batch_size=60,verbose=2,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "edff2be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.4693877696990967 \n",
      "Precision : 0.4530201256275177 \n",
      "Recall : 0.4029850661754608 \n",
      "F1Score : 0.4265402758137467\n"
     ]
    }
   ],
   "source": [
    "accuracy = hist.history['Accuracy'][-2]\n",
    "precision = hist.history['precision'][-2]\n",
    "recall = hist.history['recall'][-2]\n",
    "F1Scrore = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"Accuracy : {accuracy} \\nPrecision : {precision} \\nRecall : {recall} \\nF1Score : {F1Scrore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddf7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d77d12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elmoformanylangs.elmo import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af18fdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 14:57:17,687 WARNING: Could not find config.  Trying C:/Users/RizzWann/Downloads/Compressed/177\\cnn_50_100_512_4096_sample.json\n",
      "2023-04-28 14:57:17,689 WARNING: Could not find config.  Trying C:\\Users\\RizzWann\\anaconda3\\lib\\site-packages\\elmoformanylangs\\configs\\cnn_50_100_512_4096_sample.json\n",
      "2023-04-28 14:57:17,709 INFO: char embedding size: 3272\n",
      "2023-04-28 14:57:18,570 INFO: word embedding size: 171020\n",
      "2023-04-28 14:57:24,619 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(171020, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(3272, 50, padding_idx=3269)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "e = Embedder('C:/Users/RizzWann/Downloads/Compressed/177')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6faadbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector_elmo(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += e.sents2elmo(word)[0][0].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "                         \n",
    "            continue\n",
    "    if count != 0.:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.corpous.apply(lambda x: str(x).split()) # tokenizing\n",
    "wordvec_arrays = np.zeros((len(corpus), 1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b13eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    wordvec_arrays[i,:] = word_vector_elmo(corpus[i],1024)\n",
    "    \n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78998329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f61f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df.to_csv(\"E:/DS/Datasets/elmo_urdu_emb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba31ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 1024)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = pd.read_csv('E:/DS/Datasets/elmo_urdu_emb.csv')\n",
    "wordvec_arrays = wordvec_arrays.values\n",
    "wordvec_arrays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ce6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainSize = int(df.shape[0]*0.75)\n",
    "num_words = len(corpus)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.corpous, df.Class,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test  = X_test.astype(str)\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=128,truncating='post',padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=128,truncating='pre',padding='pre')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4564e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 128, 1024)         1003520   \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 128, 200)          735600    \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 100)               90600     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,829,821\n",
      "Trainable params: 826,301\n",
      "Non-trainable params: 1,003,520\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "12/12 - 16s - loss: 0.8337 - Accuracy: 0.5262 - precision: 0.5188 - recall: 0.4119 - val_loss: 0.7386 - val_Accuracy: 0.4966 - val_precision: 0.4966 - val_recall: 1.0000 - 16s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "12/12 - 10s - loss: 0.7265 - Accuracy: 0.4825 - precision: 0.4660 - recall: 0.4090 - val_loss: 0.7034 - val_Accuracy: 0.4966 - val_precision: 0.4966 - val_recall: 1.0000 - 10s/epoch - 831ms/step\n",
      "Epoch 3/10\n",
      "12/12 - 9s - loss: 0.7069 - Accuracy: 0.4869 - precision: 0.4811 - recall: 0.6090 - val_loss: 0.6927 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 9s/epoch - 786ms/step\n",
      "Epoch 4/10\n",
      "12/12 - 10s - loss: 0.7088 - Accuracy: 0.4825 - precision: 0.4682 - recall: 0.4388 - val_loss: 0.6926 - val_Accuracy: 0.5068 - val_precision: 1.0000 - val_recall: 0.0068 - 10s/epoch - 817ms/step\n",
      "Epoch 5/10\n",
      "12/12 - 10s - loss: 0.7127 - Accuracy: 0.4825 - precision: 0.4569 - recall: 0.3164 - val_loss: 0.6968 - val_Accuracy: 0.4966 - val_precision: 0.4966 - val_recall: 1.0000 - 10s/epoch - 806ms/step\n",
      "Epoch 6/10\n",
      "12/12 - 9s - loss: 0.6964 - Accuracy: 0.5175 - precision: 0.5132 - recall: 0.2896 - val_loss: 0.6943 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 9s/epoch - 790ms/step\n",
      "Epoch 7/10\n",
      "12/12 - 10s - loss: 0.6975 - Accuracy: 0.4898 - precision: 0.4676 - recall: 0.3015 - val_loss: 0.6970 - val_Accuracy: 0.4966 - val_precision: 0.4966 - val_recall: 1.0000 - 10s/epoch - 826ms/step\n",
      "Epoch 8/10\n",
      "12/12 - 9s - loss: 0.7091 - Accuracy: 0.4840 - precision: 0.4768 - recall: 0.5522 - val_loss: 0.6980 - val_Accuracy: 0.5034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 9s/epoch - 783ms/step\n",
      "Epoch 9/10\n",
      "12/12 - 10s - loss: 0.6923 - Accuracy: 0.5364 - precision: 0.5344 - recall: 0.4179 - val_loss: 0.7211 - val_Accuracy: 0.4966 - val_precision: 0.4966 - val_recall: 1.0000 - 10s/epoch - 816ms/step\n",
      "Epoch 10/10\n",
      "12/12 - 10s - loss: 0.7128 - Accuracy: 0.4942 - precision: 0.4762 - recall: 0.3582 - val_loss: 0.6992 - val_Accuracy: 0.4966 - val_precision: 0.4966 - val_recall: 1.0000 - 10s/epoch - 812ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(wordvec_arrays),\n",
    "                            output_dim=1024,\n",
    "                            weights=[wordvec_arrays],\n",
    "                            input_length=128,\n",
    "                            trainable=False),\n",
    "    GRU(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    GRU(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Accuracy',\n",
    "                                                                     'Precision',\n",
    "                                                                     'Recall',\n",
    "                                                                   \n",
    "                                                \n",
    "                                                                    ])\n",
    "print(model.summary())\n",
    "\n",
    "hist = model.fit(X_train,y_train,epochs=10,batch_size=60,verbose=2,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d226aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5364431738853455 \n",
      "Precision : 0.5343511700630188 \n",
      "Recall : 0.41791045665740967 \n",
      "F1Score : 0.46901174053507994\n"
     ]
    }
   ],
   "source": [
    "accuracy = hist.history['Accuracy'][-2]\n",
    "precision = hist.history['precision'][-2]\n",
    "recall = hist.history['recall'][-2]\n",
    "F1Scrore = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"Accuracy : {accuracy} \\nPrecision : {precision} \\nRecall : {recall} \\nF1Score : {F1Scrore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271a14b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('C:/Users/RizzWann/Downloads/Compressed/glove.6B/glove.6B.300d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3477670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    " print(embeddings_index.get('گھر'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a658f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector_glove(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += embeddings_index.get(word).reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "                         \n",
    "            continue\n",
    "    if count != 0.:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc95f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "corpus = df.corpous.apply(lambda x: str(x).split())\n",
    "vocab_size = len(corpus) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for i in range(len(corpus)):\n",
    "    embedding_matrix[i,:] = word_vector_glove(corpus[i], 300)\n",
    "    print(i)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def589a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainSize = int(df.shape[0]*0.75)\n",
    "num_words = len(corpus)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.corpous, df.Class,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test  = X_test.astype(str)\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=128,truncating='post',padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=128,truncating='pre',padding='pre')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e94998",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(embedding_matrix),\n",
    "                            output_dim=300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=128,\n",
    "                            trainable=False),\n",
    "    GRU(200, dropout=0.3, activation='tanh', return_sequences=True),\n",
    "    GRU(100, dropout=0.3, activation='tanh'),\n",
    "    Dense(1,'sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Accuracy',\n",
    "                                                                     'Precision',\n",
    "                                                                     'Recall',\n",
    "                                                                   \n",
    "                                                \n",
    "                                                                    ])\n",
    "print(model.summary())\n",
    "\n",
    "hist = model.fit(X_train,y_train,epochs=10,batch_size=60,verbose=2,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f222803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "     -------------------------------------- 68.8/68.8 kB 156.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\rizzwann\\anaconda3\\envs\\practicestats\\lib\\site-packages (from fasttext) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\rizzwann\\anaconda3\\envs\\practicestats\\lib\\site-packages (from fasttext) (61.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rizzwann\\anaconda3\\envs\\practicestats\\lib\\site-packages (from fasttext) (1.21.5)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'done'\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-win_amd64.whl size=229474 sha256=692331dd3dd86ea82e7f73975dc1e10ac781778a54e750e50b43c41deedcb7bf\n",
      "  Stored in directory: c:\\users\\rizzwann\\appdata\\local\\pip\\cache\\wheels\\64\\57\\bc\\1741406019061d5664914b070bd3e71f6244648732bc96109e\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ables (c:\\users\\rizzwann\\anaconda3\\envs\\practicestats\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ables (c:\\users\\rizzwann\\anaconda3\\envs\\practicestats\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f138f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42c77351",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Empty vocabulary. Try a smaller -minCount value.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_unsupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:DS/check.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PracticeStats\\lib\\site-packages\\fasttext\\FastText.py:559\u001b[0m, in \u001b[0;36mtrain_unsupervised\u001b[1;34m(*kargs, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m a \u001b[38;5;241m=\u001b[39m _build_args(args, manually_set_args)\n\u001b[0;32m    558\u001b[0m ft \u001b[38;5;241m=\u001b[39m _FastText(args\u001b[38;5;241m=\u001b[39ma)\n\u001b[1;32m--> 559\u001b[0m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m ft\u001b[38;5;241m.\u001b[39mset_args(ft\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mgetArgs())\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ft\n",
      "\u001b[1;31mValueError\u001b[0m: Empty vocabulary. Try a smaller -minCount value."
     ]
    }
   ],
   "source": [
    "model = fasttext.train_unsupervised('E:DS/check.txt', dim=300, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbba56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
